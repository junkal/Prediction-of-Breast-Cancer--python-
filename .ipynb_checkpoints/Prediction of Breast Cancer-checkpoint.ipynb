{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-machine-learning/resources/bANLa) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of Breast Cancer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Breast Cancer Wisconsin (Diagnostic) Database, we can create a classifier that can help diagnose patients and predict the likelihood of a breast cancer. A few machine learning techniques will be explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis\n",
    "\n",
    "Load the dataset and do some quick exploratory analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "            ...             radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           ...                    25.38          17.33           184.60   \n",
       "1           ...                    24.99          23.41           158.80   \n",
       "2           ...                    23.57          25.53           152.50   \n",
       "3           ...                    14.91          26.50            98.87   \n",
       "4           ...                    22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv', index_col=False)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 32)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
       "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
       "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
       "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
       "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean           ...             radius_worst  texture_worst  \\\n",
       "count     569.000000           ...               569.000000     569.000000   \n",
       "mean        0.181162           ...                16.269190      25.677223   \n",
       "std         0.027414           ...                 4.833242       6.146258   \n",
       "min         0.106000           ...                 7.930000      12.020000   \n",
       "25%         0.161900           ...                13.010000      21.080000   \n",
       "50%         0.179200           ...                14.970000      25.410000   \n",
       "75%         0.195700           ...                18.790000      29.720000   \n",
       "max         0.304000           ...                36.040000      49.540000   \n",
       "\n",
       "       perimeter_worst   area_worst  smoothness_worst  compactness_worst  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       fractal_dimension_worst  \n",
       "count               569.000000  \n",
       "mean                  0.083946  \n",
       "std                   0.018061  \n",
       "min                   0.055040  \n",
       "25%                   0.071460  \n",
       "50%                   0.080040  \n",
       "75%                   0.092080  \n",
       "max                   0.207500  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is not large. The good thing is that we can run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing\n",
    "\n",
    "First thing to do is to enumerate the diagnosis column such that M = 1, B = 0. Then, I set the ID column to be the index of the dataframe. Afterall, the ID column will not be used for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['diagnosis'] = data['diagnosis'].apply(lambda x: '1' if x == 'M' else '0')\n",
    "data = data.set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the number of Benign and Maglinant cases from the dataset. From the output shown below, majority of the cases are benign (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagnosis\n",
      "0    357\n",
      "1    212\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.groupby('diagnosis').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll split the data into predictor variables and target variable, following by breaking them into train and test sets. We will use 20% of the data as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['diagnosis'].values\n",
    "X = data.drop('diagnosis', axis=1).values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split (X, Y, test_size = 0.20, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline algorithm checking\n",
    "\n",
    "From the dataset, we will analysis and build a model to predict if a given set of symptoms lead to breast cancer. This is a binary classification problem, and a few algorithms are appropriate for use. Since we do not know which one will perform the best at the point, we will do a quick test on the few appropriate algorithms with default setting to get an early indication of how each of them perform. We will use 10 fold cross validation for each testing.\n",
    "\n",
    "The following non-linear algorithms will be used, namely: **Classification and Regression Trees (CART)**, **Linear Support Vector Machines (SVM)**, **Gaussian Naive Bayes (NB)** and **k-Nearest Neighbors (KNN)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = []\n",
    "models_list.append(('CART', DecisionTreeClassifier()))\n",
    "models_list.append(('SVM', SVC())) \n",
    "models_list.append(('NB', GaussianNB()))\n",
    "models_list.append(('KNN', KNeighborsClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART: 0.918841 (0.045169) (run time: 0.082179)\n",
      "SVM: 0.619614 (0.082882) (run time: 0.114747)\n",
      "NB: 0.940773 (0.033921) (run time: 0.012958)\n",
      "KNN: 0.927729 (0.055250) (run time: 0.017749)\n"
     ]
    }
   ],
   "source": [
    "num_folds = 10\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models_list:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=123)\n",
    "    start = time.time()\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "    end = time.time()\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print( \"%s: %f (%f) (run time: %f)\" % (name, cv_results.mean(), cv_results.std(), end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEVCAYAAAAb/KWvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuEtSCxnuktRChrsktdD/B1zcWYxMuO29AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1136462b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Performance Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the initial run, it looks like GaussianNB, KNN and CART performed the best given the dataset (all above 92% mean accuracy). Support Vector Machine has a surprisingly bad performance here. However, if we standardise the input dataset, it's performance should improve.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of algorithm on Standardised Data\n",
    "\n",
    "The performance of the few machine learning algorithm could be improved if a standardised dataset is being used. The improvement is likely for all the models. I will use pipelines that standardize the data and build the model for each fold in the cross-validation test harness. That way we can get a fair estimation of how each model with standardized data might perform on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledCART: 0.929710 (0.039225) (run time: 0.080529)\n",
      "ScaledSVM: 0.964879 (0.038621) (run time: 0.044158)\n",
      "ScaledNB: 0.931932 (0.038625) (run time: 0.015958)\n",
      "ScaledKNN: 0.958357 (0.038595) (run time: 0.029151)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Standardize the dataset\n",
    "pipelines = []\n",
    "\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART',\n",
    "                                                                        DecisionTreeClassifier())])))\n",
    "pipelines.append(('ScaledSVM', Pipeline([('Scaler', StandardScaler()),('SVM', SVC( ))])))\n",
    "pipelines.append(('ScaledNB', Pipeline([('Scaler', StandardScaler()),('NB',\n",
    "                                                                      GaussianNB())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN',\n",
    "                                                                       KNeighborsClassifier())])))\n",
    "results = []\n",
    "names = []\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    kfold = KFold(n_splits=num_folds, random_state=123)\n",
    "    for name, model in pipelines:\n",
    "        start = time.time()\n",
    "        cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "        end = time.time()\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        print( \"%s: %f (%f) (run time: %f)\" % (name, cv_results.mean(), cv_results.std(), end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEVCAYAAADn6Y5lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1136c4e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Performance Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the drastic improvement of SVM after using scaled data. \n",
    "\n",
    "Next, we'll fine tune the performance of SVM by tuning the algorithm\n",
    "\n",
    "## Algorithm Tuning - Tuning SVM\n",
    "\n",
    "We will focus on SVM for the algorithm tuning. We can tune **two** key parameter of the SVM algorithm - the value of C and the type of kernel. The default C for SVM is 1.0 and the kernel is Radial Basis Function (RBF). We will use the grid search method using 10-fold cross-validation with a standardized copy of the sample training dataset. We will try over a combination of C values and the following kernel types 'linear', 'poly', 'rbf' and 'sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.969231 using {'C': 2.0, 'kernel': 'rbf'}\n",
      "0.964835 (0.026196) with: {'C': 0.1, 'kernel': 'linear'}\n",
      "0.826374 (0.058723) with: {'C': 0.1, 'kernel': 'poly'}\n",
      "0.940659 (0.038201) with: {'C': 0.1, 'kernel': 'rbf'}\n",
      "0.949451 (0.032769) with: {'C': 0.1, 'kernel': 'sigmoid'}\n",
      "0.962637 (0.029474) with: {'C': 0.3, 'kernel': 'linear'}\n",
      "0.868132 (0.051148) with: {'C': 0.3, 'kernel': 'poly'}\n",
      "0.958242 (0.031970) with: {'C': 0.3, 'kernel': 'rbf'}\n",
      "0.958242 (0.033368) with: {'C': 0.3, 'kernel': 'sigmoid'}\n",
      "0.956044 (0.030933) with: {'C': 0.5, 'kernel': 'linear'}\n",
      "0.881319 (0.050677) with: {'C': 0.5, 'kernel': 'poly'}\n",
      "0.964835 (0.029906) with: {'C': 0.5, 'kernel': 'rbf'}\n",
      "0.953846 (0.026785) with: {'C': 0.5, 'kernel': 'sigmoid'}\n",
      "0.953846 (0.031587) with: {'C': 0.7, 'kernel': 'linear'}\n",
      "0.885714 (0.038199) with: {'C': 0.7, 'kernel': 'poly'}\n",
      "0.967033 (0.037271) with: {'C': 0.7, 'kernel': 'rbf'}\n",
      "0.953846 (0.028513) with: {'C': 0.7, 'kernel': 'sigmoid'}\n",
      "0.951648 (0.028834) with: {'C': 0.9, 'kernel': 'linear'}\n",
      "0.887912 (0.038950) with: {'C': 0.9, 'kernel': 'poly'}\n",
      "0.967033 (0.037271) with: {'C': 0.9, 'kernel': 'rbf'}\n",
      "0.949451 (0.034009) with: {'C': 0.9, 'kernel': 'sigmoid'}\n",
      "0.953846 (0.026546) with: {'C': 1.0, 'kernel': 'linear'}\n",
      "0.890110 (0.038311) with: {'C': 1.0, 'kernel': 'poly'}\n",
      "0.967033 (0.033027) with: {'C': 1.0, 'kernel': 'rbf'}\n",
      "0.947253 (0.032755) with: {'C': 1.0, 'kernel': 'sigmoid'}\n",
      "0.956044 (0.025765) with: {'C': 1.3, 'kernel': 'linear'}\n",
      "0.894505 (0.039427) with: {'C': 1.3, 'kernel': 'poly'}\n",
      "0.967033 (0.028188) with: {'C': 1.3, 'kernel': 'rbf'}\n",
      "0.942857 (0.031144) with: {'C': 1.3, 'kernel': 'sigmoid'}\n",
      "0.958242 (0.024765) with: {'C': 1.5, 'kernel': 'linear'}\n",
      "0.896703 (0.039791) with: {'C': 1.5, 'kernel': 'poly'}\n",
      "0.967033 (0.028188) with: {'C': 1.5, 'kernel': 'rbf'}\n",
      "0.940659 (0.035237) with: {'C': 1.5, 'kernel': 'sigmoid'}\n",
      "0.956044 (0.021766) with: {'C': 1.7, 'kernel': 'linear'}\n",
      "0.903297 (0.033409) with: {'C': 1.7, 'kernel': 'poly'}\n",
      "0.967033 (0.024479) with: {'C': 1.7, 'kernel': 'rbf'}\n",
      "0.945055 (0.035539) with: {'C': 1.7, 'kernel': 'sigmoid'}\n",
      "0.956044 (0.021766) with: {'C': 2.0, 'kernel': 'linear'}\n",
      "0.909890 (0.033680) with: {'C': 2.0, 'kernel': 'poly'}\n",
      "0.969231 (0.022370) with: {'C': 2.0, 'kernel': 'rbf'}\n",
      "0.931868 (0.028237) with: {'C': 2.0, 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "c_values = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\n",
    "kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "param_grid = dict(C=c_values, kernel=kernel_values)\n",
    "model = SVC()\n",
    "kfold = KFold(n_splits=num_folds, random_state=21)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the most accurate configuration was SVM with an **RBF** kernel and **C=1.5**, with the accuracy of **96.92%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of SVC on dataset\n",
    "\n",
    "Let's fit the SVM to the dataset and see how it performs given the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Time: 0.003409\n"
     ]
    }
   ],
   "source": [
    "# prepare the model\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "model = SVC(C=2.0, kernel='rbf')\n",
    "start = time.time()\n",
    "model.fit(X_train_scaled, Y_train)\n",
    "end = time.time()\n",
    "print( \"Run Time: %f\" % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate accuracy on test dataset\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "predictions = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.991228\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99        75\n",
      "          1       0.97      1.00      0.99        39\n",
      "\n",
      "avg / total       0.99      0.99      0.99       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score %f\" % accuracy_score(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74  1]\n",
      " [ 0 39]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we achieve an accuracy of 99.1% on the held-out test dataset. From the confusion matrix, there is only 1 case of mis-classification. The performance of this algorithm is expected to be high given the symptoms for breast cancer should exchibit certain clear patters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What else could be done\n",
    "\n",
    "One of the biggest thing that could be done is to test the algorithm on KNN and GausianNB in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "f9SY5",
   "launcher_item_id": "oxndk",
   "part_id": "mh1Vo"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
